{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SABdXmtadliZ"
   },
   "source": [
    "# 第 3 章 使用流程鏈串接物件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-XApyJ43zIxV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import grandalf\n",
    "\n",
    "from rich import print as pprint\n",
    "from operator import attrgetter, itemgetter\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.runnables import RunnableBranch, RunnableLambda, RunnableParallel, RunnablePassthrough, RunnableSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = \"sk-None-vowLahS2p4mOq6FP56VCT3BlbkFJTY1umKuhsfu61iHTNVDc\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCGtKgSU_XxaFGFbPCEt3H4uTmP3tOrAFg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekVOvjVlUAOS"
   },
   "source": [
    "## 3-1 認識LCEL（LangChain Expression Language）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fk2dXmyCdJel"
   },
   "source": [
    "### 1. 簡單使用 LCEL\n",
    "可以使用`|`把prompt，LLM，parser串起來成一個chain，再使用`invoke`直接得到想要的輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yqegkd0O8f2Z",
    "outputId": "a221830e-be29-40e3-cbd9-ed1fd0ce71f1"
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template('{city} 位於那一個國家？')\n",
    "chat_model = ChatOpenAI()\n",
    "str_parser = StrOutputParser()\n",
    "chain = prompt | chat_model | str_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "W_mCOdQ-N-EG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "台北位於中華民國（台灣）。\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"city\":\"台北\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90tV6e5mMy5d"
   },
   "source": [
    "### 2. 手工串接個別物件\n",
    "如果沒有`|`的話，我們就得自己寫Python把這些東西串起來了，多不方便啊！此外，想加入新的東西也會很麻煩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MnTA7QpPDgDa",
    "outputId": "ce8d12b4-7fba-445f-937a-035dc06b994c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "台北是位於中華民國（台灣）的首都。\n"
     ]
    }
   ],
   "source": [
    "content = str_parser.invoke(chat_model.invoke(prompt.invoke({'city': '台北'})))\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "1CTHTPiaFvnK",
    "outputId": "912d3922-ab79-4018-e80d-82e2fb200535"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'日本。'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class make_chain:\n",
    "    def __init__(self, runnable_list):\n",
    "        self.__runnable_list = runnable_list\n",
    "    def invoke(self, arg):\n",
    "        for runnable in self.__runnable_list:\n",
    "            arg = runnable.invoke(arg)\n",
    "        return arg\n",
    "\n",
    "find_country_chain = make_chain([prompt, chat_model, str_parser])\n",
    "find_country_chain.invoke({'city': '京都'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTBnsk8DM8JA"
   },
   "source": [
    "### 3. 使用 RunnableSequence 類別簡化多層函式的呼叫\n",
    "`RunnableSequence`的功能跟LCEL是一樣的，只是不如LCEL精簡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "oN-RvHUgJzpK",
    "outputId": "707bba0f-9baa-4e47-e4b1-c927dd27884f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York 位於美國。'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_country_chain = RunnableSequence(prompt, chat_model, str_parser)\n",
    "find_country_chain.invoke({'city': 'New York'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiNc7XpyNNRx"
   },
   "source": [
    "### 4. 使用 RunnableParallel 以相同參數執行並整合多個 Runnable 物件\n",
    "將相同參數傳入多個不同的chain時（可以想像成Chain的並聯），可以使用`RunnableParallel`物件。例如以下定義一個`find_lang_chain`的chain，我們想pass一樣的參數進去`find_lang_chain`和剛剛定義的`find_country_chain`，可以這麼做"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "g6I1gm0DP1uL",
    "outputId": "d1d4a5cf-2f73-47f6-eddc-c414be5d65ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'在開羅，主要使用的語言是阿拉伯語。此外，英語也是一種常用的第二語言，許多人也能夠使用法語或其他外語。'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_template = ChatPromptTemplate.from_template('在{city}講哪一種語言？')\n",
    "find_lang_chain = lang_template | chat_model | str_parser\n",
    "find_lang_chain.invoke({'city': '開羅'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立`RunnableParallel`物件時，甚至可以隨意的塞入沒定義過得變數作為輸出的key。例如之前的程式根本沒定義`country`跟`lang`兩變數，但`RunnableParallel`物件會讓這個並聯的chain的回傳成為「以這兩個變數名稱為key的字典」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_88dpb1QrTs",
    "outputId": "7bca49c4-18e1-405e-d520-6aa433f49011"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': '開羅是位於埃及的首都。',\n",
       " 'lang': '在開羅，人們主要講阿拉伯語。此外，英語也是一種廣泛使用的語言，特別是在商業和旅遊領域。其他常見的語言包括法語和意大利語。'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_country_and_lang_chain = RunnableParallel(country=find_country_chain, lang=find_lang_chain)\n",
    "find_country_and_lang_chain.invoke({'city': '開羅'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以用字典建立`RunnableParallel`物件，比較不會造成誤會"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BzJtXDlIiBeh",
    "outputId": "674047ec-f63d-4298-bf9b-1a2cba7bb6b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': '香港位於中國的一個特別行政區。',\n",
       " 'lang': '在香港，主要使用的語言是粤語（廣東話），是當地的官方語言。此外，普通話（國語）也廣泛使用，尤其在商業和政府場合。英語也是香港的官方語言之一，普遍被用於商務和教育領域。其他常見的語言包括客家話、潮州話和其他方言。'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_country_and_lang_chain = RunnableParallel({'country': find_country_chain, 'lang': find_lang_chain})\n",
    "find_country_and_lang_chain.invoke({'city': '香港'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當字典（value必須是callable的物件！）跟一個`Runnable`物件以`|`接起來時，該字典會自動變成`RunnableParallel`物件。可以想像成兩個callable的物件並聯後再與第三個物件做串聯。例如以下的`summary_template`，他的功能是把前兩個並聯的chain的output接在一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "PklYepnkkdZe",
    "outputId": "60e567dc-6a4f-4606-fe0c-229435ba0fe9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatPromptValue</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">messages</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'釜山位於南韓。在釜山，主要使用的語言是韓語。釜山是韓國第二大城市，因此韓語是當地最常用的語言。</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">此外，部分人口也會使用英語或其他外語。'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatPromptValue\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mmessages\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcontent\u001b[0m=\u001b[32m'釜山位於南韓。在釜山，主要使用的語言是韓語。釜山是韓國第二大城市，因此韓語是當地最常用的語言。\u001b[0m\n",
       "\u001b[32m此外，部分人口也會使用英語或其他外語。'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_template = ChatPromptTemplate.from_template('{country}{lang}')\n",
    "summary_chain = {'country': find_country_chain, 'lang': find_lang_chain} | summary_template # 先並聯再串聯\n",
    "pprint(summary_chain.invoke({'city': '釜山'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cz50acdYNr6A"
   },
   "source": [
    "## 3-2 LCEL 實用功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tB0r-qDKNQ2P"
   },
   "source": [
    "### 1. 串接可呼叫物件\n",
    "`|`也可以拿來串聯函式等可呼叫的物件。比如說，以下的`attrgetter`是一個可以取得物件屬性的函式，而`itemgetter`則是可以獲取串列中指定位置元素的函式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Kh8p9xsYwxFv"
   },
   "outputs": [],
   "source": [
    "get_messages = attrgetter('messages')\n",
    "get_first_item = itemgetter(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比如說，以下的Chain，會先由`summary_chain`獲得`ChatPromptValue`的回傳值，接著`get_messages`會取出該`ChatPromptValue`物件中的`messages`屬性（為一串列），`get_first_item`取出message的第一個元素，最後由`str_parser`解析器輸出成字串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "xIyzLfxHwygT",
    "outputId": "23e5dbcb-dd72-42be-d136-5818a813bf5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'台中位於中國台灣。在台中主要講中文，也就是國語或台語。台中是台灣的中部城市，大部分居民使用中文作為溝通的主要語言。此外，台中也有一些外籍人士，他們可能使用英文或其他語言溝通。'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = (summary_chain | get_messages | get_first_item | str_parser)\n",
    "summary.invoke({'city': '台中'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXq9YHOwNUc_"
   },
   "source": [
    "### 2. 使用 RunnablePassthrough 搭配 RunnableParallel 簡化傳入參數\n",
    "`RunnablePassthrough`可以用來把字串直接傳入chain中，單獨使用時就是一個identical mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "DAyyth2Aw0Fw",
    "outputId": "36217f73-a3d0-4a58-bd79-0e965f4b1812"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'台北'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = RunnablePassthrough()\n",
    "r.invoke(\"台北\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用以下的技巧省去`invoke`時需要傳送字典的不方便"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "VmOGyWmVw1g9",
    "outputId": "4336e5ff-5385-49cc-9d86-3a90785b72f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'台中位於台灣。在台中主要使用的語言是中文，也就是普通話或國語。此外，台中也有一部分人口使用台語或客家話。英文在觀光景點或商業場所也會被使用。'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = {'city': RunnablePassthrough()} | summary\n",
    "summary.invoke('台中')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1muHzzOcWbdJ"
   },
   "source": [
    "### 3. RunnableBinding物件\n",
    "`RunnableBinding`物件可以用來指定額外的參數。例如`Runnable`物件底下的`bind`方法，其中的stop參數可以使模型一講到其中的關鍵字就停止輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cTwlpAPnYJYr",
    "outputId": "a0bd8c78-1800-4209-e83e-eee58e956efa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "台北是位於\n"
     ]
    }
   ],
   "source": [
    "chain = {\"city\": RunnablePassthrough()} | prompt.bind() | chat_model.bind(stop=[\"台灣\",\"臺灣\"]) | str_parser\n",
    "print(chain.invoke(\"台北\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GblY0YqGX6qG"
   },
   "source": [
    "又比方說我們可以用`Pydantic`定義工具給LLM使用。定義出的工具，藉由模型的`bind_tools`方法來使用。比如我們定義一個網路搜尋工具（只是範例，它沒有作用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Pu6yMiM2ltR5"
   },
   "outputs": [],
   "source": [
    "class Search(BaseModel):\n",
    "    \"\"\"網路搜尋工具\"\"\"\n",
    "    search_input: str = Field(description=\"應該要搜尋的關鍵字\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當使用`bind_tools`之後，`Pydantic`物件轉為OpenAI function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "Km0_FRnnpZsA",
    "outputId": "b163b10a-39ef-4d78-db76-d19615a8106e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Search'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'網路搜尋工具'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'object'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'properties'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'search_input'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'應該要搜尋的關鍵字'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'string'</span><span style=\"font-weight: bold\">}}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'required'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'search_input'</span><span style=\"font-weight: bold\">]</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'type'\u001b[0m: \u001b[32m'function'\u001b[0m,\n",
       "        \u001b[32m'function'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'Search'\u001b[0m,\n",
       "            \u001b[32m'description'\u001b[0m: \u001b[32m'網路搜尋工具'\u001b[0m,\n",
       "            \u001b[32m'parameters'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'type'\u001b[0m: \u001b[32m'object'\u001b[0m,\n",
       "                \u001b[32m'properties'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'search_input'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'description'\u001b[0m: \u001b[32m'應該要搜尋的關鍵字'\u001b[0m, \u001b[32m'type'\u001b[0m: \u001b[32m'string'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'required'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'search_input'\u001b[0m\u001b[1m]\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = chat_model.bind_tools([Search])\n",
    "pprint(model.kwargs[\"tools\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下這個chain，會將`invoke`的參數當成`prompt`中的`city`，拿去給`model`使用，而`model`會將剛剛該參數傳給定義出的`Search`物件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "4El7wgaudquX",
    "outputId": "5c6fef0c-c4fa-44d3-987b-6f050399118e"
   },
   "outputs": [],
   "source": [
    "chain = ({\"city\": RunnablePassthrough()} | prompt | model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Search'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'args'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'search_input'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'台北 位於那一個國家'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'call_RB90nkSV6xFDvayxA1U90kIm'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'tool_call'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'name'\u001b[0m: \u001b[32m'Search'\u001b[0m,\n",
       "        \u001b[32m'args'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'search_input'\u001b[0m: \u001b[32m'台北 位於那一個國家'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'id'\u001b[0m: \u001b[32m'call_RB90nkSV6xFDvayxA1U90kIm'\u001b[0m,\n",
       "        \u001b[32m'type'\u001b[0m: \u001b[32m'tool_call'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(chain.invoke(\"台北\").tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當想要知道chain裡面的工具的資訊時，可以使用`JsonOutputToolsParser`，這對使用OpenAI function calling非常有幫助"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Xz0k8IgMYrDq"
   },
   "outputs": [],
   "source": [
    "tools_parser = JsonOutputToolsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "JiracWimlwc2",
    "outputId": "f72ad5f1-9964-4243-cb9e-33c43e6b65b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'args'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'search_input'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'台北 位於那一個國家？'</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Search'</span><span style=\"font-weight: bold\">}]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'args'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'search_input'\u001b[0m: \u001b[32m'台北 位於那一個國家？'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'type'\u001b[0m: \u001b[32m'Search'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain = {\"city\": RunnablePassthrough()} | prompt | model | tools_parser\n",
    "pprint(chain.invoke(\"台北\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VeMShb9VP8H"
   },
   "source": [
    "### 4. 分支與合併\n",
    "現在我們展示LCEL真正強大的地方。我們可以把一個大問題拆解成一連串的chain，但是把中間的思考過程隱藏起來。比如想要問「珍珠奶茶起源於哪裡」，可以拆解成兩個問題：「誰發明了珍珠奶茶？」以及「該人是哪國人？」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "sO9ByuR5aX7r",
    "outputId": "b7ef4b98-aaf1-45e7-f126-dbe703bc1c76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'珍珠奶茶最早起源於台灣。'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_template = ChatPromptTemplate.from_template(\"是誰發明{invention}？\")\n",
    "country_template = ChatPromptTemplate.from_template(\"{person}來自哪個國家？\")\n",
    "\n",
    "person_chain = ({\"invention\": RunnablePassthrough()}\n",
    "              | person_template\n",
    "              | chat_model\n",
    "              | str_parser)\n",
    "\n",
    "person_summary_chain = ({\"person\": person_chain} # invoke的參數會先被丟進`person_chain`\n",
    "                        | country_template\n",
    "                        | chat_model\n",
    "                        | str_parser)\n",
    "\n",
    "person_summary_chain.invoke(\"珍珠奶茶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYFpA98lGgh4"
   },
   "source": [
    "### 5. 多個提示模板\n",
    "甚至還可以把每個chain視為一個節點，組成一張單向圖，完成邏輯較為複雜的任務"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比方說一個JK要根據自己當天的心情決定穿搭，他的決策方式如下：\n",
    "1. 由自己的心情決定衣服\n",
    "2. 由衣服決定下半身的搭配\n",
    "3. 由衣服決定配戴的飾品\n",
    "4. 綜合1~3作為一整套穿搭\n",
    "\n",
    "則這個過程可以用4個prompt概括："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "-UvYRbk5QGNN"
   },
   "outputs": [],
   "source": [
    "json_parser = JsonOutputParser()\n",
    "format_instructions = json_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制定提示模板\n",
    "prompt1 = ChatPromptTemplate.from_template(\"假設你是日本女高中生，且你今天的心情十分{emotion}，請為自己挑選一件衣服。請僅提供該衣服的名稱：\") \n",
    "prompt2 = ChatPromptTemplate.from_template(\"{cloth}這種衣服通常會搭配哪種裙子？請僅提供該裙子的名稱：{format_instructions}\")\n",
    "prompt2 = prompt2.partial(format_instructions=format_instructions)\n",
    "prompt3 = ChatPromptTemplate.from_template(\"哪種飾品配合{cloth}最搭配？請僅提供飾品名稱：\")\n",
    "prompt4 = ChatPromptTemplate.from_template(\"請結合{cloth}，{skirt}和{accessory}，這樣的穿搭適合和朋友到哪些地方逛街\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把決策的過程使用3條chain串起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "iGHxd_0NaduL"
   },
   "outputs": [],
   "source": [
    "emotion_to_cloth = {\"emotion\": RunnablePassthrough()} | prompt1 | chat_model | str_parser\n",
    "cloth_to_skirt = prompt2 | chat_model | json_parser\n",
    "cloth_to_accessory = prompt3 | chat_model | str_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cloth(input_dict):\n",
    "    return {\"cloth\": input_dict, \"input\": input_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_generator = (emotion_to_cloth\n",
    "    | extract_cloth\n",
    "    | {\n",
    "        \"skirt\": cloth_to_skirt | itemgetter(\"裙子\"),  # RunnableParallel\n",
    "        \"accessory\": cloth_to_accessory,\n",
    "        \"cloth\": RunnablePassthrough()  # Ensure cloth is preserved\n",
    "    }\n",
    "    | prompt4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fs9pG7kvaiyl",
    "outputId": "cbd16ad7-d222-4b81-dc74-493be31345d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最終產生的問題：請結合{'cloth': '黑色皮夾克', 'input': '黑色皮夾克'}，迷你裙和1. 銀色項鍊\n",
      "2. 手鍊\n",
      "3. 銀色戒指\n",
      "4. 墨鏡，這樣的穿搭適合和朋友到哪些地方逛街\n",
      "\n",
      "AI 回答結果：這樣的穿搭搭配迷你裙和黑色皮夾克，再搭配銀色項鍊、手鍊、銀色戒指和墨鏡，非常適合和朋友到時尚街區或購物中心逛街。這樣的穿搭既時尚又有型，可以展現個人的時尚品味，同時也非常適合在商店或咖啡廳裡享受閒暇時光。無論是逛街購物還是享受下午茶，這樣的穿搭都能讓你煥然一新，散發自信和魅力。\n"
     ]
    }
   ],
   "source": [
    "prompt = question_generator.invoke(\"長期素食導致變成不爽世\")\n",
    "print(\n",
    "    f\"最終產生的問題：{prompt.messages[0].content}\\n\\n\"\n",
    "    f\"AI 回答結果：{chat_model.invoke(prompt).content}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "甚至還可以把這個決策圖給畫出來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nanKlXUQfufL",
    "outputId": "d2244bd1-4862-4521-ffef-b95199fb5bd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             +------------------------+                              \n",
      "                             | Parallel<emotion>Input |                              \n",
      "                             +------------------------+                              \n",
      "                                          *                                          \n",
      "                                          *                                          \n",
      "                                          *                                          \n",
      "                                  +-------------+                                    \n",
      "                                  | Passthrough |                                    \n",
      "                                  +-------------+                                    \n",
      "                                          *                                          \n",
      "                                          *                                          \n",
      "                                          *                                          \n",
      "                               +--------------------+                                \n",
      "                               | ChatPromptTemplate |                                \n",
      "                               +--------------------+                                \n",
      "                                          *                                          \n",
      "                                          *                                          \n",
      "                                          *                                          \n",
      "                                   +------------+                                    \n",
      "                                   | ChatOpenAI |                                    \n",
      "                                   +------------+                                    \n",
      "                                          *                                          \n",
      "                                          *                                          \n",
      "                                          *                                          \n",
      "                                +-----------------+                                  \n",
      "                                | StrOutputParser |                                  \n",
      "                                +-----------------+                                  \n",
      "                                          *                                          \n",
      "                                          *                                          \n",
      "                                          *                                          \n",
      "                                  +---------------+                                  \n",
      "                                  | extract_cloth |                                  \n",
      "                                  +---------------+                                  \n",
      "                                          *                                          \n",
      "                                          *                                          \n",
      "                                          *                                          \n",
      "                      +--------------------------------------+                       \n",
      "                      | Parallel<skirt,accessory,cloth>Input |                       \n",
      "                      +--------------------------------------+                       \n",
      "                        ******            *            ******                        \n",
      "                   *****                  *                  *****                   \n",
      "                ***                       *                       *****              \n",
      "+--------------------+                    *                            ***           \n",
      "| ChatPromptTemplate |                    *                              *           \n",
      "+--------------------+                    *                              *           \n",
      "           *                              *                              *           \n",
      "           *                              *                              *           \n",
      "           *                              *                              *           \n",
      "    +------------+                        *                   +--------------------+ \n",
      "    | ChatOpenAI |                        *                   | ChatPromptTemplate | \n",
      "    +------------+                        *                   +--------------------+ \n",
      "           *                              *                              *           \n",
      "           *                              *                              *           \n",
      "           *                              *                              *           \n",
      " +------------------+                     *                       +------------+     \n",
      " | JsonOutputParser |                     *                       | ChatOpenAI |     \n",
      " +------------------+                     *                       +------------+     \n",
      "           *                              *                              *           \n",
      "           *                              *                              *           \n",
      "           *                              *                              *           \n",
      "      +--------+                  +-------------+               +-----------------+  \n",
      "      | Lambda |***               | Passthrough |               | StrOutputParser |  \n",
      "      +--------+   *****          +-------------+            ***+-----------------+  \n",
      "                        ******            *            ******                        \n",
      "                              *****       *       *****                              \n",
      "                                   ***    *    ***                                   \n",
      "                      +---------------------------------------+                      \n",
      "                      | Parallel<skirt,accessory,cloth>Output |                      \n",
      "                      +---------------------------------------+                      \n",
      "                                          *                                          \n",
      "                                          *                                          \n",
      "                                          *                                          \n",
      "                               +--------------------+                                \n",
      "                               | ChatPromptTemplate |                                \n",
      "                               +--------------------+                                \n",
      "                                          *                                          \n",
      "                                          *                                          \n",
      "                                          *                                          \n",
      "                            +--------------------------+                             \n",
      "                            | ChatPromptTemplateOutput |                             \n",
      "                            +--------------------------+                             \n"
     ]
    }
   ],
   "source": [
    "question_generator.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是要注意的是，很多個chain這樣串在一起時往往很難debug，而不斷的invoke又會浪費錢。建議真的有問題可以丟給ChatGPT請他幫你生可以跑的code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIHrNMUUMZZu"
   },
   "source": [
    "## 3-3 LCEL 函式應用與分支合併"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OejhtwKgMgKo"
   },
   "source": [
    "### 1. `RunnableLambda`物件\n",
    "可以用`RunnableLambda`物件用來定義自己的`Runnable`物件，使其可以應用`invoke`方法並可以用`|`併入chain中。注意`RunnableLambda`物件包裝的函數只能有單一參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Paa50mLIMi4j"
   },
   "outputs": [],
   "source": [
    "def commodity(food):\n",
    "    # 定義每個商店的商品和價格\n",
    "    items = {\"熱狗\": 50, \"漢堡\": 70, \"披薩\": 100}\n",
    "    item = items.get(food)\n",
    "    print(f\"{food}價格：{item}\")\n",
    "    return {\"price\": item}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YaREXYXMMjlu",
    "outputId": "46e52b81-4437-4b24-d3b7-4390b6952d73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "披薩價格：100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'price': 100}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food=RunnableLambda(commodity)\n",
    "food.invoke(\"披薩\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cKwb4PjUMlCQ",
    "outputId": "b129adcc-9c79-4ed2-c82f-7885856c4cb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "漢堡價格：70\n",
      "選擇的商品總共要花費70元。\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"我選擇的商品要多少錢？數量{number}價錢{price}\")\n",
    "chain = (\n",
    "    {\n",
    "        'price':itemgetter(\"food\") | RunnableLambda(commodity), # 並聯\n",
    "        'number':itemgetter(\"number\")\n",
    "    }\n",
    "    | prompt\n",
    "    | chat_model\n",
    "    | str_parser\n",
    ")\n",
    "print(chain.invoke({\"food\":\"漢堡\", \"number\":\"101\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看起來用的模型滿笨的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQSCqVsnMoRu"
   },
   "source": [
    "### 2. 依照輸入的分類執行不同任務\n",
    "如果我們希望依據輸入的不同來進行不同的任務，我們可以怎麼做呢？比方說，\n",
    "1. 當使用者用命令的語氣說話時，希望模型都以「是的，主人」開頭\n",
    "2. 當使用者詢問知識形問題時，希望模型都以「根據我的知識」開頭。\n",
    "#### (1) 土法煉鋼\n",
    "我們可以先定義出一個分類器來分辨命令或查詢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "dxDTDWZjMmdp"
   },
   "outputs": [],
   "source": [
    "classifier = (PromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                    根據使用者問題作回答, 將問題分為要求命令或是查詢答案。\\n\n",
    "                    <問題>\\n{question}\\n</問題>\\n\n",
    "                    分類:\n",
    "                \"\"\")\n",
    "              | chat_model \n",
    "              | str_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6tetbozPMqOG",
    "outputId": "a08a8e43-0d75-41b2-8609-837b4ad84dbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "要求命令\n",
      "查詢答案\n"
     ]
    }
   ],
   "source": [
    "print(classifier.invoke({\"question\": \"這是最後的警告，今後不要再和我扯上關係了\"}))\n",
    "print(classifier.invoke({\"question\": \"為什麼要演奏春日影！？\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著根據兩種情況分別定義不同的chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "F0mV0yvHMreq"
   },
   "outputs": [],
   "source": [
    "order_chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"你不會思考只根據命令做回應, 每次回答開頭都以 '是的, 主人' \"\n",
    "        \"回覆命令\\n\"\n",
    "        \"問題: {question}\\n\"\n",
    "        \"回覆:\"\n",
    "    )\n",
    "    | chat_model\n",
    ")\n",
    "ask_chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"你只能回答知識性相關問題, 任何要求命令不會照做也不會回答,\"\n",
    "        \"每次回答開頭都以 '根據我的知識' 回覆命令\\n\"\n",
    "        \"問題: {question}\"\n",
    "        \"回覆:\"\n",
    "    )\n",
    "    | chat_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "並定義一個default的情形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "defult_chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"請回答問題:\\n\"\n",
    "        \"問題: {question}\\n\"\n",
    "        \"回覆:\"\n",
    "    )\n",
    "    | chat_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將這些chain組合起來，並直接使用`if-else`判斷要使用哪一個chain來回答問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "5XrM90B9MuVR"
   },
   "outputs": [],
   "source": [
    "def route(info):\n",
    "    if \"查詢答案\" in info[\"topic\"]:\n",
    "        return ask_chain\n",
    "    elif \"要求命令\" in info[\"topic\"]:\n",
    "        return order_chain\n",
    "    else:\n",
    "        return defult_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "3yJM9RazMvhQ"
   },
   "outputs": [],
   "source": [
    "full_chain = ({\"topic\":classifier, \"question\": lambda x: x[\"question\"]}\n",
    "             | RunnableLambda(route)\n",
    "             | str_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       +-------------------------------+    \n",
      "       | Parallel<topic,question>Input |    \n",
      "       +-------------------------------+    \n",
      "                **            **            \n",
      "              **                **          \n",
      "            **                    **        \n",
      "+----------------+                  **      \n",
      "| PromptTemplate |                   *      \n",
      "+----------------+                   *      \n",
      "          *                          *      \n",
      "          *                          *      \n",
      "          *                          *      \n",
      "  +------------+                     *      \n",
      "  | ChatOpenAI |                     *      \n",
      "  +------------+                     *      \n",
      "          *                          *      \n",
      "          *                          *      \n",
      "          *                          *      \n",
      "+-----------------+             +--------+  \n",
      "| StrOutputParser |             | Lambda |  \n",
      "+-----------------+             +--------+  \n",
      "                **            **            \n",
      "                  **        **              \n",
      "                    **    **                \n",
      "      +--------------------------------+    \n",
      "      | Parallel<topic,question>Output |    \n",
      "      +--------------------------------+    \n",
      "                       *                    \n",
      "                       *                    \n",
      "                       *                    \n",
      "                   +-------+                \n",
      "                   | route |                \n",
      "                   +-------+                \n",
      "                       *                    \n",
      "                       *                    \n",
      "                       *                    \n",
      "              +-----------------+           \n",
      "              | StrOutputParser |           \n",
      "              +-----------------+           \n",
      "                       *                    \n",
      "                       *                    \n",
      "                       *                    \n",
      "           +-----------------------+        \n",
      "           | StrOutputParserOutput |        \n",
      "           +-----------------------+        \n"
     ]
    }
   ],
   "source": [
    "full_chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m32gW0oHMxrZ",
    "outputId": "10d8ea23-8aed-488b-a07e-06c871aaf3ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是的, 主人。我會去幫您買東西。\n",
      "根據我的知識，北極圈是在緯度66.5度以上。\n"
     ]
    }
   ],
   "source": [
    "print(full_chain.invoke({\"question\": \"去幫我買東西\"}))\n",
    "print(full_chain.invoke({\"question\": \"北極圈是在緯度多少以上？\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQHdH2UQMzUr"
   },
   "source": [
    "#### (2) RunnableBranch\n",
    "如果需要LLM進行分類的時候可以建立`RunnableBranch`物件，達成跟剛剛的`route`一樣的事情。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "LWIbz26YM0TE"
   },
   "outputs": [],
   "source": [
    "branch = RunnableBranch(\n",
    "    (lambda x: \"查詢答案\" in x[\"topic\"], ask_chain),\n",
    "    (lambda x: \"要求命令\" in x[\"topic\"], order_chain),\n",
    "    defult_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "jzDPvyz7M1mG"
   },
   "outputs": [],
   "source": [
    "full_chain = ({\"topic\": classifier, \n",
    "               \"question\": lambda x: x[\"question\"]} # 並聯\n",
    "              | branch\n",
    "              | str_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bhxOX7qGM2OH",
    "outputId": "47f95411-c642-4a7d-cc82-3838ae2d45d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是的, 主人，命令收到\n",
      "是的, 主人，GPT4機智無窮\n",
      "是的, 主人，詩句如流水\n",
      "是的, 主人，創作無限好\n",
      "根據我的知識，GPT2有1.5億個參數。\n"
     ]
    }
   ],
   "source": [
    "print(full_chain.invoke({\"question\": \"以GPT4為題寫一首七言絕句\"}))\n",
    "print(full_chain.invoke({\"question\": \"GPT2有多少參數？\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyyz774IM4QP"
   },
   "source": [
    "### 3. 更換模型或提示\n",
    "Google的gemini也支援langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0axnTGzM-nt",
    "outputId": "564637cc-0217-49eb-942f-8752d20412f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508 公尺\n"
     ]
    }
   ],
   "source": [
    "gemini = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "print(gemini.invoke(\"台灣101有多高？\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) `ConfigurableField`物件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IsCgwEeNB16"
   },
   "source": [
    "可以建立`ConfigurableField`物件，使得chain可以使用各種想要的語言模型。其中`id`將會用來切換模型使用，其餘的`name`以及`description`則是說明。以下列例子來說，可以使用字典`{'llm': \"gpt4\"}`來切換模型給GPT-4 turbo，或是以`{'llm': gemini'}`來切換到Gemini-pro，而預設的`llm`（`default_key`）是GPT-3.5 turbo。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "ycW87wDiNAH6"
   },
   "outputs": [],
   "source": [
    "llm = chat_model.configurable_alternatives(\n",
    "    ConfigurableField(id=\"llm\", name=\"LLM\", description=\"多種語言模型\"), # 預設模型 gpt-3.5-turbo\n",
    "    default_key = \"openai\",\n",
    "    gpt4 = ChatOpenAI(model=\"gpt-4-turbo\"), # 新增模型 gpt-4-turbo   \n",
    "    gemini = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7) # 新增模型 gemini-pro\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-Ga7DWxNFc3",
    "outputId": "b15787d8-fc3d-448c-c857-affcd531b0f8"
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"請回答問題{topic}\")\n",
    "chain = prompt | llm | str_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3grn2pOvNHYl",
    "outputId": "62248423-2eb9-4f8e-9a2a-e5bdc7265c01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"春日影\" 的具體含義可能因文化或語境而異。如果你指的是一首具體的曲目或樂曲，通常演奏特定的音樂作品可以有以下幾個原因：\n",
      "\n",
      "1. **表達情感或氛圍**：音樂是一種強大的表達工具，能夠傳達深刻的情感和創造特定的氛圍。例如，如果\"春日影\"是一首描繪春天的樂曲，演奏它可能用以喚起春天的感覺，如新生、希望和美麗的自然景觀。\n",
      "\n",
      "2. **文化或節日慶典**：在某些文化中，特定的音樂作品可能與特定的節日或慶典活動相關聯。演奏這樣的音樂可以作為慶祝或紀念這些事件的一部分。\n",
      "\n",
      "3. **藝術欣賞和教育**：演奏經典或重要的音樂作品可以是音樂教育的一部分，旨在培養聽眾或學生對不同音樂風格、作曲家或音樂歷史的理解和欣賞。\n",
      "\n",
      "4. **個人或團體的展示**：音樂會或表演可以是音樂家展示其技巧和表達力的機會。演奏特定的作品可以展示演奏者的能力以及其對音樂的解讀。\n",
      "\n",
      "如果\"春日影\"指的是其他類型的表現形式或有特定的背景，可能需要更多的具體信息來準確回答為什么選擇演奏它。如果能提供更多細節，我可以提供更精確的解釋或分析。\n"
     ]
    }
   ],
   "source": [
    "print(chain.with_config(configurable={\"llm\": \"gpt4\"}).invoke({\"topic\": \"為什麼要演奏春日影？\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o8N6TVN_NIlH",
    "outputId": "9264f2f2-6803-469d-dbdc-eca7dc79b45f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "演奏《春日影》的主要原因包括：\n",
      "\n",
      "**藝術表達：**\n",
      "\n",
      "* 《春日影》是一首優美而抒情的樂曲，表現了春天的溫馨和美好。\n",
      "* 演奏這首樂曲可以讓音樂家表達他們的藝術性，並與聽眾分享他們的音樂感受。\n",
      "\n",
      "**技術提升：**\n",
      "\n",
      "* 《春日影》要求精湛的演奏技巧，包括靈活的手指、敏銳的音準和對節奏的控制。\n",
      "* 練習和演奏這首樂曲可以幫助音樂家提高他們的演奏能力。\n",
      "\n",
      "**文化傳承：**\n",
      "\n",
      "* 《春日影》是日本傳統音樂中的重要曲目，代表了日本文化中對春天的讚美。\n",
      "* 演奏這首樂曲有助於傳承日本音樂傳統，並促進對日本文化的欣賞。\n",
      "\n",
      "**情感宣洩：**\n",
      "\n",
      "* 《春日影》的旋律優美動聽，能激發聽眾的情感。\n",
      "* 演奏這首樂曲可以幫助音樂家表達他們的喜悅、希望和對自然的欣賞。\n",
      "\n",
      "**娛樂和享受：**\n",
      "\n",
      "* 《春日影》是一首令人愉悅的樂曲，聽眾和演奏者都能從中獲得樂趣。\n",
      "* 演奏這首樂曲可以創造輕鬆和愉快的氛圍。\n",
      "\n",
      "**其他原因：**\n",
      "\n",
      "* 參加比賽或考試\n",
      "* 作為教學材料\n",
      "* 促進音樂素養\n",
      "* 探索不同的文化\n"
     ]
    }
   ],
   "source": [
    "print(chain.with_config(configurable={\"llm\": \"gemini\"}).invoke({\"topic\": \"為什麼要演奏春日影？\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM們又在鬼扯了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f96yh046NMTt"
   },
   "source": [
    "#### (2) `PromptTemplate`物件\n",
    "`PromptTemplate`也可以塞入`ConfigurableField`物件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "ccN6LiIGNNO4"
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"告訴我一個{topic}相關知識\").configurable_alternatives(\n",
    "    ConfigurableField(id=\"prompt\", name=\"提示模板\", description=\"多種提示\"),\n",
    "    default_key=\"knowledge\", # 預設模板\n",
    "    discuss=PromptTemplate.from_template(\"根據顏色{color}列出可能的水果\"), # 新增提示模板\n",
    "    chat=ChatPromptTemplate.from_messages([(\"system\",\"你是一個動物專家\"),\n",
    "                                           (\"human\",\"相關特徵有{topic}, 請猜出是十二生肖的哪一個動物\")]) # 新增對話提示模板\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "跟剛剛的`llm`串成一個chain。要怎麼使用呢？只要調用chain的`with_config`方法，將以字典指定`configurable`，就能同時指定`prompt`和`llm`的參數。接著`invoke`時只要塞入與`prompt`對應的參數即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Hsul_dRNOkf",
    "outputId": "78fec85c-52d5-4fbb-aedf-b3c0ac8b5e94"
   },
   "outputs": [],
   "source": [
    "chain = prompt | llm | str_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 蘋果\n",
      "- 草莓\n",
      "- 紅櫻桃\n",
      "- 覆盆子\n",
      "- 石榴\n",
      "- 紅提\n",
      "- 紅莓\n",
      "- 紅柿\n",
      "- 紅毛桃\n"
     ]
    }
   ],
   "source": [
    "print(chain.with_config(configurable={\"prompt\": \"discuss\", \"llm\": \"openai\"}).invoke({\"color\": \"紅色\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意Gemini現在尚不支援`ChatPromptTemplate`輸入！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vWjNfV94NO-J",
    "outputId": "eb4cd222-69c1-4a38-e6fb-cee67cc118e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**貓貓蟲咖波**\n",
      "\n",
      "**分類：**\n",
      "* 動物界\n",
      "* 節肢動物門\n",
      "* 昆蟲綱\n",
      "* 鱗翅目\n",
      "* 蛾科\n",
      "* 貓貓蟲亞科\n",
      "\n",
      "**特徵：**\n",
      "\n",
      "* **外觀：**貓貓蟲咖波體長約 2.5-3 公分，具有蓬鬆、毛絨絨的黑色或深棕色身軀，頭部有兩個大眼睛和觸角。\n",
      "* **幼蟲：**幼蟲稱為「毛毛蟲」，身體佈滿長毛，以桉樹葉為食。\n",
      "* **防禦機制：**受到威脅時，咖波會將身體縮成一團，露出其鮮豔的橙色內側，以震懾掠食者。\n",
      "* **發聲：**咖波會發出獨特的「咔咔」聲，作為求偶或警告信號。\n",
      "\n",
      "**棲息地：**\n",
      "咖波原產於紐西蘭，棲息在南島的溫帶雨林中。\n",
      "\n",
      "**食性：**\n",
      "咖波主要以桉樹葉為食。\n",
      "\n",
      "**繁殖：**\n",
      "咖波每年只繁殖一次。雌性會產下約 100 顆卵，卵孵化後約 10 天。\n",
      "\n",
      "**保育現況：**\n",
      "咖波曾一度瀕臨絕種，由於棲息地破壞和引進掠食者（如老鼠）。目前，咖波受到嚴格保護，並已建立了幾處保育區。\n",
      "\n",
      "**有趣事實：**\n",
      "\n",
      "* 咖波是世界上唯一不會飛的鸚鵡。\n",
      "* 咖波是夜行性動物，白天通常在樹洞或石縫中休息。\n",
      "* 咖波的平均壽命約為 20 年。\n",
      "* 咖波是紐西蘭的國寶，也是該國最具標誌性的鳥類之一。\n"
     ]
    }
   ],
   "source": [
    "print(chain.with_config(configurable={\"llm\": \"gemini\"}).invoke({\"topic\": \"貓貓蟲咖波\"}))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
