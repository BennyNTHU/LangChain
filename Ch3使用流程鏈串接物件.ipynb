{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-XApyJ43zIxV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import grandalf\n",
    "\n",
    "from rich import print as print\n",
    "from operator import attrgetter, itemgetter\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.runnables import RunnableBranch, RunnableLambda, RunnableParallel, RunnablePassthrough, RunnableSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = \"sk-None-vowLahS2p4mOq6FP56VCT3BlbkFJTY1umKuhsfu61iHTNVDc\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCGtKgSU_XxaFGFbPCEt3H4uTmP3tOrAFg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SABdXmtadliZ"
   },
   "source": [
    "# 第 3 章 建立對話機器人"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekVOvjVlUAOS"
   },
   "source": [
    "## 3-1 認識LCEL（LangChain Expression Language）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fk2dXmyCdJel"
   },
   "source": [
    "### 1. 簡單使用 LCEL\n",
    "可以使用`|`把prompt，LLM，parser串起來成一個chain，再使用`invoke`直接得到想要的輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yqegkd0O8f2Z",
    "outputId": "a221830e-be29-40e3-cbd9-ed1fd0ce71f1"
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template('{city} 位於那一個國家？')\n",
    "chat_model = ChatOpenAI()\n",
    "str_parser = StrOutputParser()\n",
    "chain = prompt | chat_model | str_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "W_mCOdQ-N-EG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "台北是台灣的首都，位於中華民國（台灣）的北部。\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"city\":\"台北\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90tV6e5mMy5d"
   },
   "source": [
    "### 2. 手工串接個別物件\n",
    "如果沒有`|`的話，我們就得自己寫Python把這些東西串起來了，多不方便啊！此外，想加入新的東西也會很麻煩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MnTA7QpPDgDa",
    "outputId": "ce8d12b4-7fba-445f-937a-035dc06b994c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "台北位於中華民國（台灣）的北部。\n"
     ]
    }
   ],
   "source": [
    "content = str_parser.invoke(chat_model.invoke(prompt.invoke({'city': '台北'})))\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "1CTHTPiaFvnK",
    "outputId": "912d3922-ab79-4018-e80d-82e2fb200535"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'日本。'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class make_chain:\n",
    "    def __init__(self, runnable_list):\n",
    "        self.__runnable_list = runnable_list\n",
    "    def invoke(self, arg):\n",
    "        for runnable in self.__runnable_list:\n",
    "            arg = runnable.invoke(arg)\n",
    "        return arg\n",
    "\n",
    "find_country_chain = make_chain([prompt, chat_model, str_parser])\n",
    "find_country_chain.invoke({'city': '京都'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTBnsk8DM8JA"
   },
   "source": [
    "### 3. 使用 RunnableSequence 類別簡化多層函式的呼叫\n",
    "`RunnableSequence`的功能跟LCEL是一樣的，只是不如LCEL精簡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "oN-RvHUgJzpK",
    "outputId": "707bba0f-9baa-4e47-e4b1-c927dd27884f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'美國'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_country_chain = RunnableSequence(prompt, chat_model, str_parser)\n",
    "find_country_chain.invoke({'city': 'New York'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiNc7XpyNNRx"
   },
   "source": [
    "### 4. 使用 RunnableParallel 以相同參數執行並整合多個 Runnable 物件\n",
    "將相同參數傳入多個不同的chain時（可以想像成Chain的並聯），可以使用`RunnableParallel`物件。例如以下定義一個`find_lang_chain`的chain，我們想pass一樣的參數進去`find_lang_chain`和剛剛定義的`find_country_chain`，可以這麼做"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "g6I1gm0DP1uL",
    "outputId": "d1d4a5cf-2f73-47f6-eddc-c414be5d65ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'在開羅，主要使用的語言是阿拉伯語。此外，也有一部分人口使用英語作為第二語言。'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_template = ChatPromptTemplate.from_template('在{city}講哪一種語言？')\n",
    "find_lang_chain = lang_template | chat_model | str_parser\n",
    "find_lang_chain.invoke({'city': '開羅'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立`RunnableParallel`物件時，甚至可以隨意的塞入沒定義過得變數作為輸出的key。例如之前的程式根本沒定義`country`跟`lang`兩變數，但`RunnableParallel`物件會讓這個並聯的chain的回傳成為「以這兩個變數名稱為key的字典」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_88dpb1QrTs",
    "outputId": "7bca49c4-18e1-405e-d520-6aa433f49011"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': '開羅位於埃及。',\n",
       " 'lang': '在開羅，通常講阿拉伯語。開羅是埃及的首都，阿拉伯語是埃及的官方語言之一。此外，也有部分人口講英語或法語等其他語言。'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_country_and_lang_chain = RunnableParallel(country=find_country_chain, lang=find_lang_chain)\n",
    "find_country_and_lang_chain.invoke({'city': '開羅'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以用字典建立`RunnableParallel`物件，比較不會造成誤會"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BzJtXDlIiBeh",
    "outputId": "674047ec-f63d-4298-bf9b-1a2cba7bb6b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': '香港位於中國的南部，是中國的特別行政區。',\n",
       " 'lang': '香港主要使用廣東話作為主要語言，此外普通話、英語和其他方言也有使用。'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_country_and_lang_chain = RunnableParallel({'country': find_country_chain, 'lang': find_lang_chain})\n",
    "find_country_and_lang_chain.invoke({'city': '香港'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當字典（value必須是callable的物件！）跟一個`Runnable`物件以`|`接起來時，該字典會自動變成`RunnableParallel`物件。可以想像成兩個callable的物件並聯後再與第三個物件做串聯。例如以下的`summary_template`，他的功能是把前兩個並聯的chain的output接在一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "PklYepnkkdZe",
    "outputId": "60e567dc-6a4f-4606-fe0c-229435ba0fe9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatPromptValue</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">messages</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'釜山位於韓國。在釜山，主要使用的語言是韓語。但是由於釜山是一個國際化的城市，也會聽到一些英語、</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">中文和日語等其他語言的使用。'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatPromptValue\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mmessages\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcontent\u001b[0m=\u001b[32m'釜山位於韓國。在釜山，主要使用的語言是韓語。但是由於釜山是一個國際化的城市，也會聽到一些英語、\u001b[0m\n",
       "\u001b[32m中文和日語等其他語言的使用。'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_template = ChatPromptTemplate.from_template('{country}{lang}')\n",
    "summary_chain = {'country': find_country_chain, 'lang': find_lang_chain} | summary_template # 先並聯再串聯\n",
    "pprint(summary_chain.invoke({'city': '釜山'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cz50acdYNr6A"
   },
   "source": [
    "## 3-2 LCEL 實用功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tB0r-qDKNQ2P"
   },
   "source": [
    "### 1. 串接可呼叫物件\n",
    "`|`也可以拿來串聯函式等可呼叫的物件。比如說，以下的`attrgetter`是一個可以取得物件屬性的函式，而`itemgetter`則是可以獲取串列中指定位置元素的函式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Kh8p9xsYwxFv"
   },
   "outputs": [],
   "source": [
    "get_messages = attrgetter('messages')\n",
    "get_first_item = itemgetter(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比如說，以下的Chain，會先由`summary_chain`獲得`ChatPromptValue`的回傳值，接著`get_messages`會取出該`ChatPromptValue`物件中的`messages`屬性（為一串列），`get_first_item`取出message的第一個元素，最後由`str_parser`解析器輸出成字串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "xIyzLfxHwygT",
    "outputId": "23e5dbcb-dd72-42be-d136-5818a813bf5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'台中位於台灣。在台中，主要講中文（普通話或台語）。另外，也有部分人口講英文或其他語言。'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = (summary_chain | get_messages | get_first_item | str_parser)\n",
    "summary.invoke({'city': '台中'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXq9YHOwNUc_"
   },
   "source": [
    "### 2. 使用 RunnablePassthrough 搭配 RunnableParallel 簡化傳入參數\n",
    "`RunnablePassthrough`可以用來把字串直接傳入chain中，單獨使用時就是一個identical mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "DAyyth2Aw0Fw",
    "outputId": "36217f73-a3d0-4a58-bd79-0e965f4b1812"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'台北'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = RunnablePassthrough()\n",
    "r.invoke(\"台北\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用以下的技巧省去`invoke`時需要傳送字典的不方便"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "VmOGyWmVw1g9",
    "outputId": "4336e5ff-5385-49cc-9d86-3a90785b72f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'台中位於台灣。台中是位於台灣的城市，居民主要使用的語言是中文，也就是普通話或台語。另外，也有少數人使用英文或其他外語。'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = {'city': RunnablePassthrough()} | summary\n",
    "summary.invoke('台中')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1muHzzOcWbdJ"
   },
   "source": [
    "### 3. RunnableBinding物件\n",
    "`RunnableBinding`物件可以用來指定額外的參數。例如`Runnable`物件底下的`bind`方法，其中的stop參數可以使模型一講到其中的關鍵字就停止輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cTwlpAPnYJYr",
    "outputId": "a0bd8c78-1800-4209-e83e-eee58e956efa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "台北是位於中華民國（\n"
     ]
    }
   ],
   "source": [
    "chain = {\"city\": RunnablePassthrough()} | prompt.bind() | chat_model.bind(stop=[\"台灣\",\"臺灣\"]) | str_parser\n",
    "print(chain.invoke(\"台北\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GblY0YqGX6qG"
   },
   "source": [
    "又比方說我們可以用`Pydantic`定義工具給LLM使用。定義出的工具，藉由模型的`bind_tools`方法來使用。比如我們定義一個網路搜尋工具（只是範例，它沒有作用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Pu6yMiM2ltR5"
   },
   "outputs": [],
   "source": [
    "class Search(BaseModel):\n",
    "    \"\"\"網路搜尋工具\"\"\"\n",
    "    search_input: str = Field(description=\"應該要搜尋的關鍵字\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當使用`bind_tools`之後，`Pydantic`物件轉為OpenAI function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "Km0_FRnnpZsA",
    "outputId": "b163b10a-39ef-4d78-db76-d19615a8106e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Search'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'網路搜尋工具'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'object'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'properties'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'search_input'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'應該要搜尋的關鍵字'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'string'</span><span style=\"font-weight: bold\">}}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'required'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'search_input'</span><span style=\"font-weight: bold\">]</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'type'\u001b[0m: \u001b[32m'function'\u001b[0m,\n",
       "        \u001b[32m'function'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'Search'\u001b[0m,\n",
       "            \u001b[32m'description'\u001b[0m: \u001b[32m'網路搜尋工具'\u001b[0m,\n",
       "            \u001b[32m'parameters'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'type'\u001b[0m: \u001b[32m'object'\u001b[0m,\n",
       "                \u001b[32m'properties'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'search_input'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'description'\u001b[0m: \u001b[32m'應該要搜尋的關鍵字'\u001b[0m, \u001b[32m'type'\u001b[0m: \u001b[32m'string'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'required'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'search_input'\u001b[0m\u001b[1m]\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = chat_model.bind_tools([Search])\n",
    "pprint(model.kwargs[\"tools\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下這個chain，會將`invoke`的參數當成`prompt`中的`city`，拿去給`model`使用，而`model`會將剛剛該參數傳給定義出的`Search`物件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "4El7wgaudquX",
    "outputId": "5c6fef0c-c4fa-44d3-987b-6f050399118e"
   },
   "outputs": [],
   "source": [
    "chain = ({\"city\": RunnablePassthrough()} | prompt | model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Search'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'args'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'search_input'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'台北 位於那一個國家'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'call_1ElaGqsaJLgwIJC5WtHEuxUj'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'tool_call'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'name'\u001b[0m: \u001b[32m'Search'\u001b[0m,\n",
       "        \u001b[32m'args'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'search_input'\u001b[0m: \u001b[32m'台北 位於那一個國家'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'id'\u001b[0m: \u001b[32m'call_1ElaGqsaJLgwIJC5WtHEuxUj'\u001b[0m,\n",
       "        \u001b[32m'type'\u001b[0m: \u001b[32m'tool_call'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(chain.invoke(\"台北\").tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當想要知道chain裡面的工具的資訊時，可以使用`JsonOutputToolsParser`，這對使用OpenAI function calling非常有幫助"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Xz0k8IgMYrDq"
   },
   "outputs": [],
   "source": [
    "tools_parser = JsonOutputToolsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "JiracWimlwc2",
    "outputId": "f72ad5f1-9964-4243-cb9e-33c43e6b65b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'args'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'search_input'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'台北'</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Search'</span><span style=\"font-weight: bold\">}]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'args'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'search_input'\u001b[0m: \u001b[32m'台北'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'type'\u001b[0m: \u001b[32m'Search'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain = {\"city\": RunnablePassthrough()} | prompt | model | tools_parser\n",
    "pprint(chain.invoke(\"台北\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VeMShb9VP8H"
   },
   "source": [
    "### 4. 分支與合併\n",
    "現在我們展示LCEL真正強大的地方。我們可以把一個大問題拆解成一連串的chain，但是把中間的思考過程隱藏起來。比如想要問「珍珠奶茶起源於哪裡」，可以拆解成兩個問題：「誰發明了珍珠奶茶？」以及「該人是哪國人？」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "sO9ByuR5aX7r",
    "outputId": "b7ef4b98-aaf1-45e7-f126-dbe703bc1c76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'臺灣'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_template = ChatPromptTemplate.from_template(\"是誰發明{invention}？\")\n",
    "country_template = ChatPromptTemplate.from_template(\"{person}來自哪個國家？\")\n",
    "\n",
    "person_chain = ({\"invention\": RunnablePassthrough()}\n",
    "              | person_template\n",
    "              | chat_model\n",
    "              | str_parser)\n",
    "\n",
    "person_summary_chain = ({\"person\": person_chain} # invoke的參數會先被丟進`person_chain`\n",
    "                        | country_template\n",
    "                        | chat_model\n",
    "                        | str_parser)\n",
    "\n",
    "person_summary_chain.invoke(\"珍珠奶茶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYFpA98lGgh4"
   },
   "source": [
    "### 5. 多個提示模板\n",
    "甚至還可以把每個chain視為一個節點，組成一張單向圖，完成邏輯較為複雜的任務"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比方說一個JK要根據自己當天的心情決定穿搭，他的決策方式如下：\n",
    "1. 由自己的心情決定衣服\n",
    "2. 由衣服決定下半身的搭配\n",
    "3. 由衣服決定配戴的飾品\n",
    "4. 綜合1~3作為一整套穿搭\n",
    "\n",
    "則這個過程可以用4個prompt概括："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "-UvYRbk5QGNN"
   },
   "outputs": [],
   "source": [
    "json_parser = JsonOutputParser()\n",
    "format_instructions = json_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制定提示模板\n",
    "prompt1 = ChatPromptTemplate.from_template(\"假設你是日本女高中生，且你今天的心情十分{emotion}，請為自己挑選一件衣服。請僅提供該衣服的名稱：\") \n",
    "prompt2 = ChatPromptTemplate.from_template(\"{cloth}這種衣服通常會搭配哪種裙子？請僅提供該裙子的名稱：{format_instructions}\")\n",
    "prompt2 = prompt2.partial(format_instructions=format_instructions)\n",
    "prompt3 = ChatPromptTemplate.from_template(\"哪種飾品配合{cloth}最搭配？請僅提供飾品名稱：\")\n",
    "prompt4 = ChatPromptTemplate.from_template(\"請結合{cloth}，{skirt}和{accessory}，這樣的穿搭適合和朋友到哪些地方逛街\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把決策的過程使用3條chain串起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "iGHxd_0NaduL"
   },
   "outputs": [],
   "source": [
    "emotion_to_cloth = {\"emotion\": RunnablePassthrough()} | prompt1 | chat_model | str_parser\n",
    "cloth_to_skirt = prompt2 | chat_model | json_parser\n",
    "cloth_to_accessory = prompt3 | chat_model | str_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cloth(input_dict):\n",
    "    return {\"cloth\": input_dict, \"input\": input_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_generator = (emotion_to_cloth\n",
    "    | extract_cloth\n",
    "    | {\n",
    "        \"skirt\": cloth_to_skirt | itemgetter(\"裙子\"),  # RunnableParallel\n",
    "        \"accessory\": cloth_to_accessory,\n",
    "        \"cloth\": RunnablePassthrough()  # Ensure cloth is preserved\n",
    "    }\n",
    "    | prompt4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fs9pG7kvaiyl",
    "outputId": "cbd16ad7-d222-4b81-dc74-493be31345d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最終產生的問題：請結合{'cloth': '黑色長袖寬鬆T恤', 'input': '黑色長袖寬鬆T恤'}，牛仔裙和1. 銀色長項鍊\n",
      "2. 黑色寬腰帶\n",
      "3. 銀色手鐲\n",
      "4. 棕色編織手提包，這樣的穿搭適合和朋友到哪些地方逛街\n",
      "\n",
      "AI 回答結果：這樣的穿搭適合和朋友到購物中心、咖啡廳或者小型市集逛街。配上牛仔裙和黑色長袖寬鬆T恤，再搭配銀色長項鍊、黑色寬腰帶、銀色手鐲以及棕色編織手提包，整體看起來時尚又舒適，適合在休閒的環境中與朋友一起享受購物樂趣。這樣的穿搭不僅適合在白天逛街，也可以輕鬆轉換成晚上的約會穿搭。\n"
     ]
    }
   ],
   "source": [
    "prompt = question_generator.invoke(\"長期素食導致變成不爽世\")\n",
    "print(\n",
    "    f\"最終產生的問題：{prompt.messages[0].content}\\n\\n\"\n",
    "    f\"AI 回答結果：{chat_model.invoke(prompt).content}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "甚至還可以把這個決策圖給畫出來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nanKlXUQfufL",
    "outputId": "d2244bd1-4862-4521-ffef-b95199fb5bd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             +------------------------+                           \n",
      "                             | Parallel<emotion>Input |                           \n",
      "                             +------------------------+                           \n",
      "                                          *                                       \n",
      "                                          *                                       \n",
      "                                          *                                       \n",
      "                                  +-------------+                                 \n",
      "                                  | Passthrough |                                 \n",
      "                                  +-------------+                                 \n",
      "                                          *                                       \n",
      "                                          *                                       \n",
      "                                          *                                       \n",
      "                               +--------------------+                             \n",
      "                               | ChatPromptTemplate |                             \n",
      "                               +--------------------+                             \n",
      "                                          *                                       \n",
      "                                          *                                       \n",
      "                                          *                                       \n",
      "                                   +------------+                                 \n",
      "                                   | ChatOpenAI |                                 \n",
      "                                   +------------+                                 \n",
      "                                          *                                       \n",
      "                                          *                                       \n",
      "                                          *                                       \n",
      "                                +-----------------+                               \n",
      "                                | StrOutputParser |                               \n",
      "                                +-----------------+                               \n",
      "                                          *                                       \n",
      "                                          *                                       \n",
      "                                          *                                       \n",
      "                                  +---------------+                               \n",
      "                                  | extract_cloth |                               \n",
      "                                  +---------------+                               \n",
      "                                          *                                       \n",
      "                                          *                                       \n",
      "                                          *                                       \n",
      "                      +--------------------------------------+                    \n",
      "                      | Parallel<skirt,accessory,cloth>Input |                    \n",
      "                      +--------------------------------------+                    \n",
      "                        ******            *            ******                     \n",
      "                   *****                  *                  *****                \n",
      "                ***                       *                       *****           \n",
      "+--------------------+                    *                            ***        \n",
      "| ChatPromptTemplate |                    *                              *        \n",
      "+--------------------+                    *                              *        \n",
      "           *                              *                              *        \n",
      "           *                              *                              *        \n",
      "           *                              *                              *        \n",
      "    +------------+             +--------------------+                    *        \n",
      "    | ChatOpenAI |             | ChatPromptTemplate |                    *        \n",
      "    +------------+             +--------------------+                    *        \n",
      "           *                              *                              *        \n",
      "           *                              *                              *        \n",
      "           *                              *                              *        \n",
      " +------------------+              +------------+                        *        \n",
      " | JsonOutputParser |              | ChatOpenAI |                        *        \n",
      " +------------------+              +------------+                        *        \n",
      "           *                              *                              *        \n",
      "           *                              *                              *        \n",
      "           *                              *                              *        \n",
      "      +--------+                +-----------------+               +-------------+ \n",
      "      | Lambda |***             | StrOutputParser |               | Passthrough | \n",
      "      +--------+   *****        +-----------------+          *****+-------------+ \n",
      "                        ******            *            ******                     \n",
      "                              *****       *       *****                           \n",
      "                                   ***    *    ***                                \n",
      "                      +---------------------------------------+                   \n",
      "                      | Parallel<skirt,accessory,cloth>Output |                   \n",
      "                      +---------------------------------------+                   \n",
      "                                          *                                       \n",
      "                                          *                                       \n",
      "                                          *                                       \n",
      "                               +--------------------+                             \n",
      "                               | ChatPromptTemplate |                             \n",
      "                               +--------------------+                             \n",
      "                                          *                                       \n",
      "                                          *                                       \n",
      "                                          *                                       \n",
      "                            +--------------------------+                          \n",
      "                            | ChatPromptTemplateOutput |                          \n",
      "                            +--------------------------+                          \n"
     ]
    }
   ],
   "source": [
    "question_generator.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是要注意的是，很多個chain這樣串在一起時往往很難debug，而不斷的invoke又會浪費錢。建議真的有問題可以丟給ChatGPT請他幫你生可以跑的code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIHrNMUUMZZu"
   },
   "source": [
    "## 3-3 LCEL 函式應用與分支合併"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OejhtwKgMgKo"
   },
   "source": [
    "### 1. `RunnableLambda`物件\n",
    "可以用`RunnableLambda`物件用來定義自己的`Runnable`物件，使其可以應用`invoke`方法並可以用`|`併入chain中。注意`RunnableLambda`物件包裝的函數只能有單一參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "Paa50mLIMi4j"
   },
   "outputs": [],
   "source": [
    "def commodity(food):\n",
    "    # 定義每個商店的商品和價格\n",
    "    items = {\"熱狗\": 50, \"漢堡\": 70, \"披薩\": 100}\n",
    "    item = items.get(food)\n",
    "    print(f\"{food}價格：{item}\")\n",
    "    return {\"price\": item}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YaREXYXMMjlu",
    "outputId": "46e52b81-4437-4b24-d3b7-4390b6952d73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "披薩價格：100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'price': 100}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food=RunnableLambda(commodity)\n",
    "food.invoke(\"披薩\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cKwb4PjUMlCQ",
    "outputId": "b129adcc-9c79-4ed2-c82f-7885856c4cb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "漢堡價格：70\n",
      "101個商品的價格為70元。\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"我選擇的商品要多少錢？數量{number}價錢{price}\")\n",
    "chain = (\n",
    "    {\n",
    "        'price':itemgetter(\"food\") | RunnableLambda(commodity), # 並聯\n",
    "        'number':itemgetter(\"number\")\n",
    "    }\n",
    "    | prompt\n",
    "    | chat_model\n",
    "    | str_parser\n",
    ")\n",
    "print(chain.invoke({\"food\":\"漢堡\", \"number\":\"101\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看起來用的模型滿笨的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQSCqVsnMoRu"
   },
   "source": [
    "### 2. 依照輸入的分類執行不同任務\n",
    "如果我們希望依據輸入的不同來進行不同的任務，我們可以怎麼做呢？比方說，\n",
    "1. 當使用者用命令的語氣說話時，希望模型都以「是的，主人」開頭\n",
    "2. 當使用者詢問知識形問題時，希望模型都以「根據我的知識」開頭。\n",
    "#### (1) 土法煉鋼\n",
    "我們可以先定義出一個分類器來分辨命令或查詢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "dxDTDWZjMmdp"
   },
   "outputs": [],
   "source": [
    "classifier = (PromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                    根據使用者問題作回答, 將問題分為要求命令或是查詢答案。\\n\n",
    "                    <問題>\\n{question}\\n</問題>\\n\n",
    "                    分類:\n",
    "                \"\"\")\n",
    "              | chat_model \n",
    "              | str_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6tetbozPMqOG",
    "outputId": "a08a8e43-0d75-41b2-8609-837b4ad84dbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "要求命令\n",
      "查詢答案\n"
     ]
    }
   ],
   "source": [
    "print(classifier.invoke({\"question\": \"這是最後的警告，今後不要再和我扯上關係了\"}))\n",
    "print(classifier.invoke({\"question\": \"為什麼要演奏春日影！？\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著根據兩種情況分別定義不同的chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "F0mV0yvHMreq"
   },
   "outputs": [],
   "source": [
    "order_chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"你不會思考只根據命令做回應, 每次回答開頭都以 '是的, 主人' \"\n",
    "        \"回覆命令\\n\"\n",
    "        \"問題: {question}\\n\"\n",
    "        \"回覆:\"\n",
    "    )\n",
    "    | chat_model\n",
    ")\n",
    "ask_chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"你只能回答知識性相關問題, 任何要求命令不會照做也不會回答,\"\n",
    "        \"每次回答開頭都以 '根據我的知識' 回覆命令\\n\"\n",
    "        \"問題: {question}\"\n",
    "        \"回覆:\"\n",
    "    )\n",
    "    | chat_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "並定義一個default的情形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "defult_chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"請回答問題:\\n\"\n",
    "        \"問題: {question}\\n\"\n",
    "        \"回覆:\"\n",
    "    )\n",
    "    | chat_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將這些chain組合起來，並直接使用`if-else`判斷要使用哪一個chain來回答問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "5XrM90B9MuVR"
   },
   "outputs": [],
   "source": [
    "def route(info):\n",
    "    if \"查詢答案\" in info[\"topic\"]:\n",
    "        return ask_chain\n",
    "    elif \"要求命令\" in info[\"topic\"]:\n",
    "        return order_chain\n",
    "    else:\n",
    "        return defult_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "3yJM9RazMvhQ"
   },
   "outputs": [],
   "source": [
    "full_chain = ({\"topic\":classifier, \"question\": lambda x: x[\"question\"]}\n",
    "             | RunnableLambda(route)\n",
    "             | str_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       +-------------------------------+    \n",
      "       | Parallel<topic,question>Input |    \n",
      "       +-------------------------------+    \n",
      "                **            **            \n",
      "              **                **          \n",
      "            **                    **        \n",
      "+----------------+                  **      \n",
      "| PromptTemplate |                   *      \n",
      "+----------------+                   *      \n",
      "          *                          *      \n",
      "          *                          *      \n",
      "          *                          *      \n",
      "  +------------+                     *      \n",
      "  | ChatOpenAI |                     *      \n",
      "  +------------+                     *      \n",
      "          *                          *      \n",
      "          *                          *      \n",
      "          *                          *      \n",
      "+-----------------+             +--------+  \n",
      "| StrOutputParser |             | Lambda |  \n",
      "+-----------------+             +--------+  \n",
      "                **            **            \n",
      "                  **        **              \n",
      "                    **    **                \n",
      "      +--------------------------------+    \n",
      "      | Parallel<topic,question>Output |    \n",
      "      +--------------------------------+    \n",
      "                       *                    \n",
      "                       *                    \n",
      "                       *                    \n",
      "                   +-------+                \n",
      "                   | route |                \n",
      "                   +-------+                \n",
      "                       *                    \n",
      "                       *                    \n",
      "                       *                    \n",
      "              +-----------------+           \n",
      "              | StrOutputParser |           \n",
      "              +-----------------+           \n",
      "                       *                    \n",
      "                       *                    \n",
      "                       *                    \n",
      "           +-----------------------+        \n",
      "           | StrOutputParserOutput |        \n",
      "           +-----------------------+        \n"
     ]
    }
   ],
   "source": [
    "full_chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m32gW0oHMxrZ",
    "outputId": "10d8ea23-8aed-488b-a07e-06c871aaf3ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是的, 主人，我會去幫您買東西。\n",
      "根據我的知識，北極圈是在緯度66.5度以上。\n"
     ]
    }
   ],
   "source": [
    "print(full_chain.invoke({\"question\": \"去幫我買東西\"}))\n",
    "print(full_chain.invoke({\"question\": \"北極圈是在緯度多少以上？\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQHdH2UQMzUr"
   },
   "source": [
    "#### (2) RunnableBranch\n",
    "如果需要LLM進行分類的時候可以建立`RunnableBranch`物件，達成跟剛剛的`route`一樣的事情。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "LWIbz26YM0TE"
   },
   "outputs": [],
   "source": [
    "branch = RunnableBranch(\n",
    "    (lambda x: \"查詢答案\" in x[\"topic\"], ask_chain),\n",
    "    (lambda x: \"要求命令\" in x[\"topic\"], order_chain),\n",
    "    defult_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "jzDPvyz7M1mG"
   },
   "outputs": [],
   "source": [
    "full_chain = ({\"topic\": classifier, \n",
    "               \"question\": lambda x: x[\"question\"]} # 並聯\n",
    "              | branch\n",
    "              | str_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bhxOX7qGM2OH",
    "outputId": "47f95411-c642-4a7d-cc82-3838ae2d45d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是的, 主人，GPT4智慧無雙，\n",
      "機器之腦，超越人類，\n",
      "推演未來，預測天象，\n",
      "創新無窮，無所不能。\n",
      "根據我的知識，GPT2有1.5億個參數。\n"
     ]
    }
   ],
   "source": [
    "print(full_chain.invoke({\"question\": \"以GPT4為題寫一首七言絕句\"}))\n",
    "print(full_chain.invoke({\"question\": \"GPT2有多少參數？\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyyz774IM4QP"
   },
   "source": [
    "### 3. 更換模型或提示\n",
    "Google的gemini也支援langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0axnTGzM-nt",
    "outputId": "564637cc-0217-49eb-942f-8752d20412f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508公尺\n"
     ]
    }
   ],
   "source": [
    "gemini = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "print(gemini.invoke(\"台灣101有多高？\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) `ConfigurableField`物件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IsCgwEeNB16"
   },
   "source": [
    "可以建立`ConfigurableField`物件，使得chain可以使用各種想要的語言模型。其中`id`將會用來切換模型使用，其餘的`name`以及`description`則是說明。以下列例子來說，可以使用字典`{'llm': \"gpt4\"}`來切換模型給GPT-4 turbo，或是以`{'llm': gemini'}`來切換到Gemini-pro，而預設的`llm`（`default_key`）是GPT-3.5 turbo。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "ycW87wDiNAH6"
   },
   "outputs": [],
   "source": [
    "llm = chat_model.configurable_alternatives(\n",
    "    ConfigurableField(id=\"llm\", name=\"LLM\", description=\"多種語言模型\"), # 預設模型 gpt-3.5-turbo\n",
    "    default_key = \"openai\",\n",
    "    gpt4 = ChatOpenAI(model=\"gpt-4-turbo\"), # 新增模型 gpt-4-turbo   \n",
    "    gemini = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7) # 新增模型 gemini-pro\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-Ga7DWxNFc3",
    "outputId": "b15787d8-fc3d-448c-c857-affcd531b0f8"
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"請回答問題{topic}\")\n",
    "chain = prompt | llm | str_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3grn2pOvNHYl",
    "outputId": "62248423-2eb9-4f8e-9a2a-e5bdc7265c01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《春日影》是一首具有中國傳統文化特色的樂曲，常見於古箏或其他中國傳統樂器的演奏。演奏這類樂曲有幾個原因：\n",
      "\n",
      "1. **文化傳承**：演奏如《春日影》這樣的傳統樂曲有助於保留和傳遞中國豐富的文化遺產。這些樂曲往往蘊含深厚的歷史和文化意義，是文化身份和傳統的重要表達。\n",
      "\n",
      "2. **藝術表達**：通過演奏傳統樂曲，演奏者可以展示其技藝，同時也能表達個人對於音樂和美的理解和感受。《春日影》等樂曲常常具有獨特的旋律和節奏，提供了一個展現個人藝術風格的平台。\n",
      "\n",
      "3. **教育和學習**：對學習中國傳統音樂的學生來說，演奏這類樂曲是學習和掌握相關樂器技巧的重要部分。它們不僅有助於提高演奏技能，也能加深對音樂理論和歷史的理解。\n",
      "\n",
      "4. **情感和心理作用**：音樂有助於調節情緒和緩解壓力。《春日影》這樣的樂曲通常具有柔和和諧的旋律，能夠帶給聽眾平靜和舒緩的感受，有益於心理健康。\n",
      "\n",
      "5. **社交和娛樂**：在節日慶典或其他社交聚會中演奏《春日影》等樂曲，可以增添氣氛，促進人們之間的交流和聯繫，並提供娛樂享受。\n",
      "\n",
      "總之，演奏《春日影》不僅是對傳統音樂的一種欣賞和練習，也是對中國文化深厚底蘊的一種展示和傳播。\n"
     ]
    }
   ],
   "source": [
    "print(chain.with_config(configurable={\"llm\": \"gpt4\"}).invoke({\"topic\": \"為什麼要演奏春日影？\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o8N6TVN_NIlH",
    "outputId": "9264f2f2-6803-469d-dbdc-eca7dc79b45f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "演奏《春日影》的原因可能包括：\n",
      "\n",
      "* **展現日本傳統音樂：**《春日影》是日本傳統音樂的代表作，演奏它可以推廣和欣賞日本文化。\n",
      "\n",
      "* **表達季節性情感：**這首曲子與春天聯繫在一起，它的旋律和節奏傳達了春天的歡樂和更新感。\n",
      "\n",
      "* **技術挑戰：**這首曲子技術要求很高，需要精湛的演奏技巧，演奏它可以展現演奏者的能力。\n",
      "\n",
      "* **文化交流：**在國際場合演奏《春日影》可以作為日本與其他文化之間交流的橋樑。\n",
      "\n",
      "* **個人表達：**演奏這首曲子可以讓音樂家表達自己的音樂性、情感和對日本傳統的欣賞。\n",
      "\n",
      "* **教育目的：**演奏《春日影》可以幫助學生了解日本音樂和文化。\n",
      "\n",
      "* **儀式或慶祝活動：**這首曲子可用於儀式或慶祝活動，例如茶道或花道。\n",
      "\n",
      "* **娛樂價值：**《春日影》是一首優美動聽的曲子，演奏它可以為聽眾帶來愉悅。\n"
     ]
    }
   ],
   "source": [
    "print(chain.with_config(configurable={\"llm\": \"gemini\"}).invoke({\"topic\": \"為什麼要演奏春日影？\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM們又在鬼扯了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f96yh046NMTt"
   },
   "source": [
    "#### (2) `PromptTemplate`物件\n",
    "`PromptTemplate`也可以塞入`ConfigurableField`物件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "ccN6LiIGNNO4"
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"告訴我一個{topic}相關知識\").configurable_alternatives(\n",
    "    ConfigurableField(id=\"prompt\", name=\"提示模板\", description=\"多種提示\"),\n",
    "    default_key=\"knowledge\", # 預設模板\n",
    "    discuss=PromptTemplate.from_template(\"根據顏色{color}列出可能的水果\"), # 新增提示模板\n",
    "    chat=ChatPromptTemplate.from_messages([(\"system\",\"你是一個動物專家\"),\n",
    "                                           (\"human\",\"相關特徵有{topic}, 請猜出是十二生肖的哪一個動物\")]) # 新增對話提示模板\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "跟剛剛的`llm`串成一個chain。要怎麼使用呢？只要調用chain的`with_config`方法，將以字典指定`configurable`，就能同時指定`prompt`和`llm`的參數。接著`invoke`時只要塞入與`prompt`對應的參數即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Hsul_dRNOkf",
    "outputId": "78fec85c-52d5-4fbb-aedf-b3c0ac8b5e94"
   },
   "outputs": [],
   "source": [
    "chain = prompt | llm | str_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "蘋果、草莓、櫻桃、紅莓、紅提、火龍果\n"
     ]
    }
   ],
   "source": [
    "print(chain.with_config(configurable={\"prompt\": \"discuss\", \"llm\": \"openai\"}).invoke({\"color\": \"紅色\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意Gemini現在尚不支援`ChatPromptTemplate`輸入！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vWjNfV94NO-J",
    "outputId": "eb4cd222-69c1-4a38-e6fb-cee67cc118e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**貓貓蟲咖波**\n",
      "\n",
      "**基本資料：**\n",
      "\n",
      "* 學名：Strigops habroptilus\n",
      "* 別名：貓頭鷹鸚鵡、紐西蘭夜鸚鵡\n",
      "* 分類：鸚鵡科（Psittacidae）\n",
      "* 體型：約 50-56 公分\n",
      "* 壽命：約 10-12 年\n",
      "\n",
      "**外觀：**\n",
      "\n",
      "* 渾身覆蓋著黃綠色羽毛，腹部為黃色，臉部有明顯的貓頭鷹狀白色面盤\n",
      "* 喙短而彎曲，呈綠色\n",
      "* 眼睛大而圓，虹膜為黃色\n",
      "* 腿短而強壯，腳趾上有鋒利的爪子\n",
      "\n",
      "**棲息地：**\n",
      "\n",
      "* 紐西蘭南島的峽灣地區和西海岸\n",
      "* 棲息於低海拔的森林和灌木叢中\n",
      "\n",
      "**習性：**\n",
      "\n",
      "* 夜行性動物，白天通常躲藏在樹洞或岩縫中\n",
      "* 以地面上的植物、水果和昆蟲為食\n",
      "* 具有獨特的舞姿，會在求偶或求雨時拍打翅膀並發出低沉的咕嚕聲\n",
      "* 非常害羞和神秘，很少被人類觀察到\n",
      "\n",
      "**保護現狀：**\n",
      "\n",
      "* 極度瀕危物種，目前僅存約 250 隻個體\n",
      "* 面臨棲息地喪失、外來物種入侵和捕食等威脅\n",
      "* 紐西蘭政府正在積極進行保護工作，包括圈養繁殖和棲息地管理\n",
      "\n",
      "**趣聞：**\n",
      "\n",
      "* 貓貓蟲咖波是紐西蘭的國鳥\n",
      "* 牠們的叫聲聽起來像貓咪的呼嚕聲\n",
      "* 牠們是世界上唯一不會飛的鸚鵡物種\n",
      "* 牠們的壽命比其他鸚鵡要短，可能是由於夜行習性和地面棲息地的緣故\n"
     ]
    }
   ],
   "source": [
    "print(chain.with_config(configurable={\"llm\": \"gemini\"}).invoke({\"topic\": \"貓貓蟲咖波\"}))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
